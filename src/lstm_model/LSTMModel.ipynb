{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Модель","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!pip install Navec","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:12:53.400029Z","iopub.status.idle":"2023-05-22T13:12:53.400792Z","shell.execute_reply.started":"2023-05-22T13:12:53.400546Z","shell.execute_reply":"2023-05-22T13:12:53.400571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:12:53.402159Z","iopub.status.idle":"2023-05-22T13:12:53.402956Z","shell.execute_reply.started":"2023-05-22T13:12:53.402697Z","shell.execute_reply":"2023-05-22T13:12:53.402722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install slovnet","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:18:37.081542Z","iopub.execute_input":"2023-05-22T13:18:37.082191Z","iopub.status.idle":"2023-05-22T13:18:48.785208Z","shell.execute_reply.started":"2023-05-22T13:18:37.082154Z","shell.execute_reply":"2023-05-22T13:18:48.783941Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting slovnet\n  Using cached slovnet-0.6.0-py3-none-any.whl (46 kB)\nCollecting razdel\n  Using cached razdel-0.5.0-py3-none-any.whl (21 kB)\nCollecting navec\n  Using cached navec-0.10.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from slovnet) (1.23.5)\nInstalling collected packages: razdel, navec, slovnet\nSuccessfully installed navec-0.10.0 razdel-0.5.0 slovnet-0.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom navec import Navec\nfrom slovnet.model.emb import NavecEmbedding\n\nimport nltk\nimport tqdm\nimport re\n\nimport torch\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:18:48.788760Z","iopub.execute_input":"2023-05-22T13:18:48.789186Z","iopub.status.idle":"2023-05-22T13:18:51.861714Z","shell.execute_reply.started":"2023-05-22T13:18:48.789143Z","shell.execute_reply":"2023-05-22T13:18:51.860772Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:18:51.863130Z","iopub.execute_input":"2023-05-22T13:18:51.863786Z","iopub.status.idle":"2023-05-22T13:18:51.895547Z","shell.execute_reply.started":"2023-05-22T13:18:51.863751Z","shell.execute_reply":"2023-05-22T13:18:51.894459Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"VOCAB_SIZE = 50000\nSEQUENCE_LEN = 5\nMAX_LINES = 1","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:18:55.025750Z","iopub.execute_input":"2023-05-22T13:18:55.026245Z","iopub.status.idle":"2023-05-22T13:18:55.031628Z","shell.execute_reply.started":"2023-05-22T13:18:55.026210Z","shell.execute_reply":"2023-05-22T13:18:55.030591Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"navec_path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\nnavec = Navec.load(navec_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:18:55.197744Z","iopub.execute_input":"2023-05-22T13:18:55.198345Z","iopub.status.idle":"2023-05-22T13:18:56.057037Z","shell.execute_reply.started":"2023-05-22T13:18:55.198306Z","shell.execute_reply":"2023-05-22T13:18:56.055648Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/russian-poetry-data/results_fin/train.csv')\ntest_dataset = pd.read_csv('/kaggle/input/russian-poetry-data/results_fin/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:40.889130Z","iopub.execute_input":"2023-05-22T13:19:40.889496Z","iopub.status.idle":"2023-05-22T13:19:41.377081Z","shell.execute_reply.started":"2023-05-22T13:19:40.889467Z","shell.execute_reply":"2023-05-22T13:19:41.376059Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset\ntest_dataset = test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:46.373974Z","iopub.execute_input":"2023-05-22T13:19:46.374348Z","iopub.status.idle":"2023-05-22T13:19:46.380975Z","shell.execute_reply.started":"2023-05-22T13:19:46.374317Z","shell.execute_reply":"2023-05-22T13:19:46.379836Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def get_list_of_verses(dataset):\n    verses = []\n    for text in dataset['poetry']:\n        lines = text.split('\\n')\n        verse = []\n        count = 0\n        for line in lines:\n            if line.strip():  # Skip empty lines\n                verse.append(line)\n                count += 1\n            if count == MAX_LINES:\n                verses.append('\\n'.join(verse))\n                verse = []\n                count = 0\n        if verse:\n            verses.append('\\n'.join(verse))\n    verses = [verse.replace('\\n', ' ') for verse in verses]\n    return verses\n\n\ndef get_vocabulary(dataset):\n    poetry_data = dataset['poetry'].values\n    all_words = ' '.join(poetry_data).split()\n    word_freq = pd.Series(all_words).value_counts().reset_index()\n    word_freq.columns = ['word', 'frequency']\n    sorted_word_freq = word_freq.sort_values(by='frequency', ascending=False)\n    top_words = [word for word in sorted_word_freq['word'] if word in navec][:VOCAB_SIZE]\n    top_words.append('<unk>')\n    return top_words\n\ndef get_word2idx(dataset):\n    poetry_data = dataset['poetry'].values\n    all_words = list(set(' '.join(poetry_data).split()))\n    word2idx = {'<pad>':navec.vocab.words.index('<pad>'), \\\n                '<unk>': navec.vocab.words.index('<unk>')}\n    for w in tqdm(all_words):\n        if w in navec:\n            word2idx[w] = navec.vocab.words.index(w)\n        else:\n            word2idx[w] = navec.vocab.words.index('<unk>')\n    return word2idx\n      \ndef get_idx2word(vocabulary):\n    idx2word = {}\n    for w in tqdm(vocabulary):\n        idx2word[navec.vocab.words.index(w)] = w\n    return idx2word","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:46.870670Z","iopub.execute_input":"2023-05-22T13:19:46.871352Z","iopub.status.idle":"2023-05-22T13:19:46.885832Z","shell.execute_reply.started":"2023-05-22T13:19:46.871317Z","shell.execute_reply":"2023-05-22T13:19:46.883509Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def batch_generator(dataset, word2idx, vocabulary, navec_path, batch_size=64, shuffle=True):\n    navec = Navec.load(navec_path)\n    \n    verse_dataset = get_list_of_verses(dataset)\n  \n    X, Y = [], []\n    for verse in verse_dataset:\n        words = verse.split()[::-1] # Reverse words\n        for i in range(len(words) - SEQUENCE_LEN):\n            if (all(word in navec for word in words[i:i + SEQUENCE_LEN])\n                and all(len(re.findall(r\"[a-zA-Z]\", word)) == 0 for word in words[i:i + SEQUENCE_LEN])):\n                if words[i + SEQUENCE_LEN] in vocabulary:\n                    X.append(tuple(words[i:i + SEQUENCE_LEN]))\n                    Y.append(words[i + SEQUENCE_LEN])\n                    \n    # We remove repeating pairs\n    unique_pairs = {}\n    for x, y in zip(X, Y):\n        unique_pairs[(x, y)] = 1\n        \n    X = [x for x, y in unique_pairs.keys()]\n    Y = [y for x, y in unique_pairs.keys()]\n          \n    n_samples = len(X)\n\n    list_of_indexes = np.linspace(\n      0, n_samples - 1, n_samples, dtype=np.int64)\n    List_X = []\n    List_Y = []\n  \n    if shuffle:\n        np.random.shuffle(list_of_indexes)\n        \n    for indx in list_of_indexes:\n        List_X.append(X[indx])\n        List_Y.append(Y[indx])\n    \n    n_batches = n_samples//batch_size\n    if n_samples % batch_size != 0:\n        n_batches += 1\n        \n    for k in range(n_batches):\n        this_batch_size = batch_size\n        \n        if k == n_batches - 1:\n            if n_samples % batch_size > 0:\n                this_batch_size = n_samples % batch_size\n                \n        This_X = List_X[k*batch_size:k*batch_size + this_batch_size]\n        This_Y = List_Y[k*batch_size:k*batch_size + this_batch_size]\n        \n        x_arr = np.zeros(shape=[len(This_X), SEQUENCE_LEN], dtype=np.int64)\n        y_arr = np.zeros(shape=[len(This_Y)], dtype=np.int64)\n        \n        for i, sequence in enumerate(This_X):\n            for j, word in enumerate(sequence):\n                x_arr[i, j] = word2idx.get(word, navec.vocab.words.index('<unk>'))\n                \n        for i, word in enumerate(This_Y):\n            target = idx2target.get(word2idx.get(word, navec.vocab.words.index('<unk>')))\n            y_arr[i] = target\n        \n        x = torch.LongTensor(x_arr)\n        y = torch.LongTensor(y_arr)\n\n        yield x, y","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:47.181208Z","iopub.execute_input":"2023-05-22T13:19:47.181602Z","iopub.status.idle":"2023-05-22T13:19:47.199064Z","shell.execute_reply.started":"2023-05-22T13:19:47.181569Z","shell.execute_reply":"2023-05-22T13:19:47.197788Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n    model.train()\n    model.zero_grad()\n    \n    output = model(batch_of_x.to(model.device))\n    loss = loss_function(output, batch_of_y.to(model.device))\n    \n    loss.backward()\n    optimizer.step()\n    \n    return loss.cpu().item()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:47.445228Z","iopub.execute_input":"2023-05-22T13:19:47.445620Z","iopub.status.idle":"2023-05-22T13:19:47.451086Z","shell.execute_reply.started":"2023-05-22T13:19:47.445587Z","shell.execute_reply":"2023-05-22T13:19:47.450145Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_epoch(train_generator,  model, loss_function, optimizer, callback=None):\n    epoch_loss = 0\n    total = 0\n    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n        local_loss = train_on_batch(\n            model, batch_of_x, batch_of_y, optimizer, loss_function)\n        train_generator.set_postfix({'train batch loss': local_loss})\n        \n        if callback is not None:\n            callback(model, local_loss)\n\n        epoch_loss += local_loss*len(batch_of_x)\n        total += len(batch_of_x)\n    \n    return epoch_loss/total","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:47.822438Z","iopub.execute_input":"2023-05-22T13:19:47.823336Z","iopub.status.idle":"2023-05-22T13:19:47.834806Z","shell.execute_reply.started":"2023-05-22T13:19:47.823299Z","shell.execute_reply":"2023-05-22T13:19:47.833803Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def trainer(count_of_epoch, \n            batch_size,\n            model,\n            train_dataset,\n            word2idx,\n            loss_function,\n            optimizer,\n            callback=None):\n    \n    iterations = tqdm(range(count_of_epoch))\n    voc = get_vocabulary(train_dataset)\n\n    for it in iterations:\n        optima = optimizer\n\n        number_of_batch = len(train_dataset)//batch_size + (len(train_dataset)%batch_size>0)\n        generator = tqdm(\n            batch_generator(train_dataset, word2idx, voc, navec_path, batch_size), \n            leave=False, total=number_of_batch)\n        \n        epoch_loss = train_epoch(\n            train_generator = generator, model = model, \n            loss_function = loss_function, \n            optimizer = optima, callback = callback)\n        \n        test_loss = test(\n            batch_generator(test_dataset, word2idx, voc, navec_path, batch_size),\n                            model, loss_function)\n\n        iterations.set_postfix({'train epoch loss': epoch_loss})\n        #print(\"Test loss: \", test_loss)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:48.175444Z","iopub.execute_input":"2023-05-22T13:19:48.176343Z","iopub.status.idle":"2023-05-22T13:19:48.185563Z","shell.execute_reply.started":"2023-05-22T13:19:48.176294Z","shell.execute_reply":"2023-05-22T13:19:48.184537Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(torch.nn.Module):\n    @property\n    def device(self):\n        return next(self.parameters()).device\n    \n    def __init__(self,\n                 hidden_dim,\n                 num_layers,\n                 output_dim,\n                 bidirectional = False,\n                 dropout=0.2):\n        super(LSTMModel, self).__init__()\n        navec_embedding = NavecEmbedding(navec)\n        \n        self.num_direction = int(bidirectional + 1)\n        self.emb_dim = 300 # navec embeddings\n        self.hidden_dim = hidden_dim\n        \n        self.embedding = navec_embedding\n        for param in navec_embedding.parameters():\n            param.requires_grad = False\n\n        \n        self.lstm = torch.nn.LSTM(\n                    self.emb_dim, hidden_dim, num_layers, dropout=dropout)\n        \n        self.linear = torch.nn.Linear(\n                     hidden_dim, output_dim)\n        self.relu = torch.nn.ReLU()\n        \n    def forward(self, input):\n        input = self.embedding(input)\n        input = torch.transpose(input, 0, 1)\n        d, _ = self.lstm(input)\n        answers = self.relu(self.linear(d[-1, :, :])) # Select the last timestep's output\n        answers.unsqueeze(1)\n        return answers","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:39:55.369504Z","iopub.execute_input":"2023-05-22T13:39:55.370191Z","iopub.status.idle":"2023-05-22T13:39:55.381604Z","shell.execute_reply.started":"2023-05-22T13:39:55.370155Z","shell.execute_reply":"2023-05-22T13:39:55.380543Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"word2idx = get_word2idx(train_dataset)\nvocabulary = get_vocabulary(train_dataset)\nidx2word = get_idx2word(vocabulary)\n\nidx2target = {word2idx[w]: i for i, w in enumerate(vocabulary)}\ntarget2idx = {i: word2idx[w] for i, w in enumerate(vocabulary)}","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:19:49.154032Z","iopub.execute_input":"2023-05-22T13:19:49.154942Z","iopub.status.idle":"2023-05-22T13:36:22.926599Z","shell.execute_reply.started":"2023-05-22T13:19:49.154895Z","shell.execute_reply":"2023-05-22T13:36:22.925571Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/137049 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e70d371647fa433a9260aab52264f758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50001 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2fd998aac39421abc58ece651be6a2a"}},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nfrom torchmetrics.functional import precision\n\nclass callback:\n    def __init__(self, writer, test_dataset, word2idx, voc, navec_path, loss_function, delimiter=18, batch_size=1024):\n        self.step = 0\n        self.writer = writer\n        self.test_dataset = test_dataset\n        self.word2idx = word2idx\n        self.delimiter = delimiter\n        self.loss_function = loss_function\n        self.batch_size = batch_size\n        self.voc = voc\n        self.navec_path = navec_path\n\n    def forward(self, model, loss):\n        self.step += 1\n        prec = 0\n        self.writer.add_scalar('lstm_final/train_loss', loss, self.step)\n\n        if self.step % self.delimiter == 0:\n            test_loss = 0\n            prec = 0\n            with torch.no_grad():\n                for batch_of_x, batch_of_y in batch_generator(self.test_dataset, self.word2idx, self.voc, self.navec_path, self.batch_size):\n                    x_batch = batch_of_x.to(model.device)\n                    y_batch = batch_of_y.to(model.device)\n                    output = model(x_batch)\n                    test_loss += self.loss_function(output, y_batch).cpu().item() * len(x_batch)\n                    #print(output.shape, y_batch.shape)\n                    prec +=  precision(output, y_batch, num_classes=len(self.voc), task='multiclass')\n                    test_loss /= len(self.test_dataset)\n                    prec /= len(self.test_dataset)\n\n\n                    self.writer.add_scalar('lstm_final/test_loss', test_loss, self.step)\n                    self.writer.add_scalar('lstm_final/test_precision', prec, self.step)\n          \n    def __call__(self, model, loss):\n        return self.forward(model, loss)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:39:58.934796Z","iopub.execute_input":"2023-05-22T13:39:58.935261Z","iopub.status.idle":"2023-05-22T13:39:58.958939Z","shell.execute_reply.started":"2023-05-22T13:39:58.935224Z","shell.execute_reply":"2023-05-22T13:39:58.957912Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = LSTMModel(output_dim=len(idx2word), num_layers=2, hidden_dim=300)\n\noptimizer = torch.optim.Adam(\n    list(model.parameters()), lr=3e-3)\nloss_function = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:39:59.099181Z","iopub.execute_input":"2023-05-22T13:39:59.102023Z","iopub.status.idle":"2023-05-22T13:39:59.349854Z","shell.execute_reply.started":"2023-05-22T13:39:59.101977Z","shell.execute_reply":"2023-05-22T13:39:59.348872Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/slovnet/model/emb.py:46: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n  torch.from_numpy(navec.pq.indexes),\n","output_type":"stream"}]},{"cell_type":"code","source":"writer = SummaryWriter(log_dir = 'lstm_final/model')\ncall = callback(writer, test_dataset, word2idx, get_vocabulary(train_dataset), \n                navec_path, loss_function, delimiter = 18)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T13:40:01.962325Z","iopub.execute_input":"2023-05-22T13:40:01.963129Z","iopub.status.idle":"2023-05-22T13:40:02.657722Z","shell.execute_reply.started":"2023-05-22T13:40:01.963091Z","shell.execute_reply":"2023-05-22T13:40:02.656734Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer(count_of_epoch = 3,\n        batch_size = 2048,\n        model = model,\n        train_dataset = train_dataset, \n        word2idx = word2idx,\n        loss_function = loss_function,\n        optimizer = optimizer,\n        callback = call)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelContainer:\n    def __init__(self, model):\n        self.model = model\n    \n    def get_model(self, list_values):\n        \n        while len(list_values) < SEQUENCE_LEN:\n            random_number = np.random.randint(0, VOCAB_SIZE - 1)\n            list_values.append(random_number)\n            \n        list_values = list_values[:SEQUENCE_LEN]\n            \n        input_tensor = torch.tensor([list_values])\n        input_tensor.to(device)\n\n        d = model(input_tensor)\n        with torch.no_grad():\n             return d.numpy()[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T18:21:31.769382Z","iopub.execute_input":"2023-05-22T18:21:31.769980Z","iopub.status.idle":"2023-05-22T18:21:31.781360Z","shell.execute_reply.started":"2023-05-22T18:21:31.769945Z","shell.execute_reply":"2023-05-22T18:21:31.780187Z"},"trusted":true},"execution_count":434,"outputs":[]},{"cell_type":"code","source":"model_container = ModelContainer(model)\nmodel_container.get_model([])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T18:21:32.222491Z","iopub.execute_input":"2023-05-22T18:21:32.222844Z","iopub.status.idle":"2023-05-22T18:21:32.242796Z","shell.execute_reply.started":"2023-05-22T18:21:32.222817Z","shell.execute_reply":"2023-05-22T18:21:32.241775Z"},"trusted":true},"execution_count":435,"outputs":[{"execution_count":435,"output_type":"execute_result","data":{"text/plain":"array([9.084438, 8.343832, 0.      , ..., 0.      , 0.      , 0.      ],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Бим path и фильтры","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/lstmmodel/model.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:16:06.797729Z","iopub.execute_input":"2023-05-22T20:16:06.798164Z","iopub.status.idle":"2023-05-22T20:16:08.724587Z","shell.execute_reply.started":"2023-05-22T20:16:06.798128Z","shell.execute_reply":"2023-05-22T20:16:08.723530Z"},"trusted":true},"execution_count":510,"outputs":[{"execution_count":510,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Рифма","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/sunn1t/Different-NLP-models-for-Russian-poetry-generation","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:59:24.488849Z","iopub.execute_input":"2023-05-22T15:59:24.489345Z","iopub.status.idle":"2023-05-22T15:59:30.416661Z","shell.execute_reply.started":"2023-05-22T15:59:24.489310Z","shell.execute_reply":"2023-05-22T15:59:30.415420Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Cloning into 'Different-NLP-models-for-Russian-poetry-generation'...\nremote: Enumerating objects: 42, done.\u001b[K\nremote: Counting objects: 100% (42/42), done.\u001b[K\nremote: Compressing objects: 100% (35/35), done.\u001b[K\nremote: Total 42 (delta 7), reused 37 (delta 5), pack-reused 0\u001b[K\nUnpacking objects: 100% (42/42), 6.53 MiB | 1.58 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd Different-NLP-models-for-Russian-poetry-generation","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:59:35.666853Z","iopub.execute_input":"2023-05-22T15:59:35.667269Z","iopub.status.idle":"2023-05-22T15:59:35.675515Z","shell.execute_reply.started":"2023-05-22T15:59:35.667232Z","shell.execute_reply":"2023-05-22T15:59:35.674603Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"/kaggle/working/Different-NLP-models-for-Russian-poetry-generation\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:00:12.629709Z","iopub.execute_input":"2023-05-22T16:00:12.630329Z","iopub.status.idle":"2023-05-22T16:00:24.189380Z","shell.execute_reply.started":"2023-05-22T16:00:12.630281Z","shell.execute_reply":"2023-05-22T16:00:24.188114Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Collecting russ==0.0.2\n  Downloading russ-0.0.2-py3-none-any.whl (23 kB)\nCollecting dicttoxml==1.7.16\n  Downloading dicttoxml-1.7.16-py3-none-any.whl (24 kB)\nCollecting jsonpickle==3.0.1\n  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pygtrie>=2.2\n  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from russ==0.0.2->-r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: transformers>=4.17.0 in /opt/conda/lib/python3.10/site-packages (from russ==0.0.2->-r requirements.txt (line 1)) (4.28.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (3.11.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (2023.3.23)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (0.13.4)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (0.13.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (2.28.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (4.64.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (2.1.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.17.0->russ==0.0.2->-r requirements.txt (line 1)) (1.26.15)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->russ==0.0.2->-r requirements.txt (line 1)) (1.3.0)\nInstalling collected packages: pygtrie, jsonpickle, dicttoxml, russ\nSuccessfully installed dicttoxml-1.7.16 jsonpickle-3.0.1 pygtrie-2.5.0 russ-0.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from src.metre_classifier.stress.dict import StressDict\nfrom src.metre_classifier.stress.predictor import CombinedStressPredictor\nfrom src.metre_classifier.markup.markup import Markup\nfrom src.metre_classifier.markup.markup import Syllable\nfrom src.metre_classifier.metre_classifier import MetreClassifier\nfrom src.metre_classifier.stress.word import Stress, StressedWord\nfrom src.metre_classifier.util.preprocess import get_first_vowel_position","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:12:33.409652Z","iopub.execute_input":"2023-05-22T16:12:33.410639Z","iopub.status.idle":"2023-05-22T16:12:33.418213Z","shell.execute_reply.started":"2023-05-22T16:12:33.410503Z","shell.execute_reply":"2023-05-22T16:12:33.416582Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"Stress('ворона', stress_predictor.predict('ворона'))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:16:55.280707Z","iopub.execute_input":"2023-05-22T16:16:55.281502Z","iopub.status.idle":"2023-05-22T16:16:55.290288Z","shell.execute_reply.started":"2023-05-22T16:16:55.281463Z","shell.execute_reply":"2023-05-22T16:16:55.289088Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"ворона\t[1, 3, 5]"},"metadata":{}}]},{"cell_type":"code","source":"{enumerate(Stress(s) for s in stress_predictor.predict(w))}","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:22:41.553618Z","iopub.execute_input":"2023-05-22T16:22:41.554331Z","iopub.status.idle":"2023-05-22T16:22:41.560743Z","shell.execute_reply.started":"2023-05-22T16:22:41.554296Z","shell.execute_reply":"2023-05-22T16:22:41.559784Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"{<enumerate at 0x7fe61990c540>}"},"metadata":{}}]},{"cell_type":"code","source":"class StressVocabulary():\n    def __init__(self, vocabulary, stress_predictor):\n        self.word_to_index = {}\n        self.index_to_word = {}\n        \n        for w in vocabulary:\n            #stress = Stress(w, stress_predictor.predict(w))\n            w_stressed = StressedWord(w, {enumerate(Stress(s) for s in stress_predictor.predict(w))})\n            self.word_to_index[w_stressed] = idx2target[word2idx[w]]\n            self.index_to_word[idx2target[word2idx[w]]] = w_stressed\n    \n    def get_word(self, index):\n        return self.index_to_word[index]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:37:56.142618Z","iopub.execute_input":"2023-05-22T17:37:56.144886Z","iopub.status.idle":"2023-05-22T17:37:56.151925Z","shell.execute_reply.started":"2023-05-22T17:37:56.144835Z","shell.execute_reply":"2023-05-22T17:37:56.150581Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"#stress_predictor = CombinedStressPredictor()\nsv = StressVocabulary(vocabulary, stress_predictor)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:37:59.810762Z","iopub.execute_input":"2023-05-22T17:37:59.811136Z","iopub.status.idle":"2023-05-22T17:38:57.869115Z","shell.execute_reply.started":"2023-05-22T17:37:59.811107Z","shell.execute_reply":"2023-05-22T17:38:57.867988Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Для рифм","metadata":{}},{"cell_type":"code","source":"VOWELS = \"aeiouAEIOUаоэиуыеёюяАОЭИУЫЕЁЮЯ\"\nCLOSED_SYLLABLE_CHARS = \"рлймнРЛЙМН\"","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:24:19.073538Z","iopub.execute_input":"2023-05-22T16:24:19.074266Z","iopub.status.idle":"2023-05-22T16:24:19.078469Z","shell.execute_reply.started":"2023-05-22T16:24:19.074228Z","shell.execute_reply":"2023-05-22T16:24:19.077548Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"from typing import List, Set\nimport copy\n\nclass Graphemes:\n    @staticmethod\n    def get_syllables(word: str) -> List[Syllable]:\n        \"\"\"\n        Разделение слова на слоги.\n        :param word: слово для разбивки на слоги.\n        :return syllables: массив слогов слова.\n        \"\"\"\n        syllables = []\n        begin = 0\n        number = 0\n\n        # В случае наличия дефиса разбиваем слова на подслова, находим слоги в них, объединяем.\n        if \"-\" in word:\n            word_parts = word.split(\"-\")\n            word_syllables = []\n            last_part_end = 0\n            for part in word_parts:\n                part_syllables = Graphemes.get_syllables(part)\n                if len(part_syllables) == 0:\n                    continue\n                for i in range(len(part_syllables)):\n                    part_syllables[i].begin += last_part_end\n                    part_syllables[i].end += last_part_end\n                    part_syllables[i].number += len(word_syllables)\n                word_syllables += part_syllables\n                last_part_end = part_syllables[-1].end + 1\n            return word_syllables\n\n        # Для слов или подслов, в которых нет дефиса.\n        for i, ch in enumerate(word):\n            if ch not in VOWELS:\n                continue\n            if i + 1 < len(word) - 1 and word[i + 1] in CLOSED_SYLLABLE_CHARS:\n                if i + 2 < len(word) - 1 and word[i + 2] in \"ьЬ\":\n                    # Если после сонорного согласного идёт мягкий знак, заканчиваем на нём. (\"бань-ка\")\n                    end = i + 3\n                elif i + 2 < len(word) - 1 and word[i + 2] not in VOWELS and \\\n                        (word[i + 2] not in CLOSED_SYLLABLE_CHARS or word[i + 1] == \"й\"):\n                    # Если после сонорного согласного не идёт гласная или другой сонорный согласный,\n                    # слог закрывается на этом согласном. (\"май-ка\")\n                    end = i + 2\n                else:\n                    # Несмотря на наличие закрывающего согласного, заканчиваем на гласной.\n                    # (\"со-ло\", \"да-нный\", \"пол-ный\")\n                    end = i + 1\n            else:\n                # Если после гласной идёт не закрывающая согласная, заканчиваем на гласной. (\"ко-гда\")\n                end = i + 1\n            syllables.append(Syllable(begin, end, number, word[begin:end]))\n            number += 1\n            begin = end\n        if get_first_vowel_position(word) != -1:\n            # Добиваем последний слог до конца слова.\n            syllables[-1] = Syllable(syllables[-1].begin, len(word), syllables[-1].number,\n                                     word[syllables[-1].begin:len(word)])\n        return syllables","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:32:36.618780Z","iopub.execute_input":"2023-05-22T17:32:36.619172Z","iopub.status.idle":"2023-05-22T17:32:36.634130Z","shell.execute_reply.started":"2023-05-22T17:32:36.619140Z","shell.execute_reply":"2023-05-22T17:32:36.632705Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"markdown","source":"# Рифмы","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nfrom typing import List\n\n# -*- coding: utf-8 -*-\n# Автор: Гусев Илья\n# Описание: Класс рифм.\n\n\nclass RhymeProfile:\n    def __init__(self, syllable_count: int, stressed_syllable_number: int,\n                 stressed_syllable_text: str, next_syllable_text: str, next_char: str):\n        self.syllable_count = syllable_count\n        self.stressed_syllable_number = stressed_syllable_number\n        self.stressed_syllable_text = stressed_syllable_text\n        self.next_syllable_text = next_syllable_text\n        self.next_char = next_char\n\n    def __str__(self):\n        return \"Syllable count: {}; Stressed syllable: {}; \" \\\n               \"Stressed syllable text: {}; Next syllable: {}; \" \\\n               \"Next char: {}\".format(self.syllable_count, self.stressed_syllable_number,\n                                      self.stressed_syllable_text, self.next_syllable_text, self.next_char)\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass Rhymes(object):\n    @staticmethod\n    def is_rhyme(word1: StressedWord, word2: StressedWord, score_border: int=4, syllable_number_border: int=4) -> bool:\n        profile1 = Rhymes.__get_rhyme_profile(word1)\n        profile2 = Rhymes.__get_rhyme_profile(word2)\n        score = 0\n        for i, ch1 in enumerate(profile1.stressed_syllable_text):\n            for j, ch2 in enumerate(profile2.stressed_syllable_text[i:]):\n                if ch1 != ch2:\n                    continue\n                if ch1 in VOWELS:\n                    score += 3\n                else:\n                    score += 1\n        if profile1.next_syllable_text == profile2.next_syllable_text and profile1.next_syllable_text != '':\n            score += 3\n        elif profile1.next_char == profile2.next_char and profile1.next_char != '':\n            score += 1\n        return (profile1.stressed_syllable_number == profile2.stressed_syllable_number and\n                profile1.syllable_count == profile2.syllable_count and\n                profile1.stressed_syllable_number <= syllable_number_border and\n                score >= score_border)\n\n    @staticmethod\n    def __get_rhyme_profile(word: StressedWord) -> 'RhymeProfile':\n        profile = RhymeProfile(syllable_count=0,\n                               stressed_syllable_number=-1,\n                               stressed_syllable_text=\"\",\n                               next_syllable_text=\"\",\n                               next_char=\"\")\n        syllables = list(word.syllables)\n        profile.syllable_count = len(syllables)\n        for i, syllable in enumerate(reversed(syllables)):\n            if syllable.stress == -1:\n                continue\n            profile.stressed_syllable_text = syllable.text\n            profile.stressed_syllable_number = -i-1\n            if i != 0:\n                profile.next_syllable = syllables[-i].text\n            if syllable.stress + 1 < len(word.text):\n                profile.next_char = word.text[syllable.stress + 1]\n            break\n        return profile","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:25:03.117651Z","iopub.execute_input":"2023-05-22T16:25:03.118204Z","iopub.status.idle":"2023-05-22T16:25:03.134556Z","shell.execute_reply.started":"2023-05-22T16:25:03.118169Z","shell.execute_reply":"2023-05-22T16:25:03.133419Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"## Фильтры","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nfrom typing import List\n\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:31:58.607762Z","iopub.execute_input":"2023-05-22T17:31:58.608443Z","iopub.status.idle":"2023-05-22T17:31:58.615223Z","shell.execute_reply.started":"2023-05-22T17:31:58.608405Z","shell.execute_reply":"2023-05-22T17:31:58.613664Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"class Filter(object):\n    def filter_model(self, model: np.array, vocabulary: StressVocabulary) -> np.array:\n        for i in range(len(model)):\n            if not self.filter_word(vocabulary.get_word(i)):\n                model[i] = 0.0\n        return model\n\n    def filter_words(self, words: List[StressedWord]) -> List[StressedWord]:\n        return [word for word in words if self.filter_word(word)]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:31:58.857493Z","iopub.execute_input":"2023-05-22T17:31:58.857809Z","iopub.status.idle":"2023-05-22T17:31:58.864252Z","shell.execute_reply.started":"2023-05-22T17:31:58.857784Z","shell.execute_reply":"2023-05-22T17:31:58.863279Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"class MetreFilter(Filter):\n    def __init__(self, metre_pattern: str):\n        self.metre_pattern = metre_pattern\n        self.position = len(metre_pattern) - 1\n\n    def filter_word(self, word: StressedWord) -> bool:\n        syllables = word.syllables\n        syllables_count = len(syllables)\n        if syllables_count == 0:\n            return False\n        if syllables_count > self.position + 1:\n            return False\n        for i in range(syllables_count):\n            syllable = syllables[i]\n            syllable_number = self.position - syllables_count + i + 1\n            if syllables_count >= 2 and syllable.stress == -1 and self.metre_pattern[syllable_number] == \"+\":\n                for j in range(syllables_count):\n                    other_syllable = syllables[j]\n                    other_syllable_number = other_syllable.number - syllable.number + syllable_number\n                    if i != j and other_syllable.stress != -1 and self.metre_pattern[other_syllable_number] == \"-\":\n                        return False\n        return True\n    def pass_word(self, word: StressedWord) -> None:\n        self.position -= len(word.syllables)\n\n    def revert_word(self, word: StressedWord) -> None:\n        self.position += len(word.syllables)\n\n    def reset(self) -> None:\n\n        self.position = len(self.metre_pattern) - 1\n\n    def is_completed(self):\n\n        return self.position < 0","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:35:14.900751Z","iopub.execute_input":"2023-05-22T17:35:14.901624Z","iopub.status.idle":"2023-05-22T17:35:14.913474Z","shell.execute_reply.started":"2023-05-22T17:35:14.901572Z","shell.execute_reply":"2023-05-22T17:35:14.912454Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"class RhymeFilter(Filter):\n    \"\"\"\n    Фильтр по шаблону рифмы.\n    \"\"\"\n    def __init__(self, rhyme_pattern: str, letters_to_rhymes: dict=None,\n                 score_border=4):\n        self.rhyme_pattern = rhyme_pattern\n        self.position = len(self.rhyme_pattern) - 1\n        self.letters_to_rhymes = defaultdict(set)\n        self.score_border = score_border\n        if letters_to_rhymes is not None:\n            for letter, words in letters_to_rhymes.items():\n                for word in words:\n                    self.letters_to_rhymes[letter].add(word)\n\n    def filter_word(self, word: StressedWord) -> bool:\n        \"\"\"\n        Фильтрация слова по рифме в текущей позиции.\n        :param word: слово.\n        :return: подходит слово или нет.\n        \"\"\"\n        if len(word.syllables) <= 1:\n            return False\n        if len(self.letters_to_rhymes[self.rhyme_pattern[self.position]]) == 0:\n            return True\n        first_word = list(self.letters_to_rhymes[self.rhyme_pattern[self.position]])[0]\n\n        is_rhyme = Rhymes.is_rhyme(first_word, word, score_border=self.score_border, syllable_number_border=2 ) and \\\n            first_word.text != word.text\n        return is_rhyme\n    \n    def pass_word(self, word: StressedWord) -> None:\n        \"\"\"\n        Сдвинуть позицию в шаблоне рифмы на строчку.\n        :param word: рифмующееся слово.\n        \"\"\"\n        self.letters_to_rhymes[self.rhyme_pattern[self.position]].add(word)\n        self.position -= 1\n\n    def revert_word(self, word: StressedWord) -> None:\n        \"\"\"\n        Сдвинуть позицию в шаблоне рифмы на строчку назад.\n        :param word: рифмующееся слово.\n        \"\"\"\n        self.position += 1\n        self.letters_to_rhymes[self.rhyme_pattern[self.position]].remove(word)\n\n    def is_completed(self):\n        \"\"\"\n        :return: закончена ли генерация по фильтру?\n        \"\"\"\n        return self.position < 0\n\n    def reset(self) -> None:\n        \"\"\"\n        Сброс позиции в шаблоне.\n        \"\"\"\n        self.position = len(self.rhyme_pattern) - 1","metadata":{"execution":{"iopub.status.busy":"2023-05-22T17:35:17.883586Z","iopub.execute_input":"2023-05-22T17:35:17.883952Z","iopub.status.idle":"2023-05-22T17:35:17.897096Z","shell.execute_reply.started":"2023-05-22T17:35:17.883923Z","shell.execute_reply":"2023-05-22T17:35:17.896052Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"class BeamPath(object):\n    def __init__(self, indices: List[int], metre_filter: MetreFilter, rhyme_filter: RhymeFilter,\n                 probability: float, line_ends: List[int]):\n        self.indices = indices  # type: List[int]\n        self.metre_filter = metre_filter  # type: MetreFilter\n        self.rhyme_filter = rhyme_filter  # type: RhymeFilter\n        self.probability = probability  # type: float\n        self.line_ends = line_ends  # type: List[int]\n\n    def put_line_end(self):\n        self.line_ends.append(len(self.indices))\n\n    def get_words(self, vocabulary: StressVocabulary) -> List[str]:\n        return [vocabulary.get_word(word_index).text.lower() for word_index in self.indices]\n\n    def get_poem(self, vocabulary: StressVocabulary) -> str:\n        words = self.get_words(vocabulary)\n        prev_end = 1\n        lines = []\n        for end in self.line_ends:\n            line = \" \".join(list(reversed(words[prev_end:end]))).capitalize()\n            prev_end = end\n            lines.append(line)\n        return \"\\n\".join(list(reversed(lines))) + \"\\n\"\n\n    def get_current_model(self, model_container: ModelContainer, vocabulary: StressVocabulary, use_rhyme: bool=False) -> np.array:\n        model = model_container.get_model(self.indices)\n        model = self.metre_filter.filter_model(model, vocabulary)\n        if use_rhyme:\n            model = self.rhyme_filter.filter_model(model, vocabulary)\n        return model\n\n    def is_empty(self) -> bool:\n        return len(self.indices) == 0\n\n    def __str__(self):\n        return str(self.metre_filter.position) + \" \" + str(self.rhyme_filter.position) + \" \" + \\\n               str(self.probability) + \" \" + str(self.indices) + \" \" + str(self.line_ends)\n\n    def __repr__(self):\n        return self.__str__()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:16:53.646126Z","iopub.execute_input":"2023-05-22T20:16:53.646617Z","iopub.status.idle":"2023-05-22T20:16:53.660337Z","shell.execute_reply.started":"2023-05-22T20:16:53.646579Z","shell.execute_reply":"2023-05-22T20:16:53.658811Z"},"trusted":true},"execution_count":511,"outputs":[]},{"cell_type":"code","source":"from numpy.random import choice\n\nclass Generator(object):\n\n    def __init__(self, model_container: ModelContainer, vocabulary: StressVocabulary,):\n\n        self.model_container = model_container  # type: ModelContainer\n        self.vocabulary = vocabulary  # type: StressVocabulary\n\n    def generate_poem(self, metre_schema: str=\"+-\", rhyme_pattern: str=\"aabb\", n_syllables: int=8,\n                      letters_to_rhymes: dict=None, beam_width: int=4, rhyme_score_border: int=4) -> str:\n\n        metre_pattern = \"\"\n        while len(metre_pattern) <= n_syllables:\n            metre_pattern += metre_schema\n        metre_pattern = metre_pattern[:n_syllables]\n        metre_filter = MetreFilter(metre_pattern)\n        rhyme_filter = RhymeFilter(rhyme_pattern, letters_to_rhymes, score_border=rhyme_score_border)\n\n        result_paths = []\n        indices = []\n        \n        empty_path = BeamPath(indices, metre_filter, rhyme_filter, 1.0, [])\n        paths = [empty_path]\n        while len(paths) != 0:\n            paths = self.__top_paths(paths, beam_width)\n            for path in paths:\n                #print(paths)\n                result_paths.append(path)\n            #for path in copy.deepcopy(paths):\n            for path in paths:\n                paths.pop(0)\n                paths += self.generate_line_beam(path, beam_width)\n            paths, to_result = self.__filter_path_by_rhyme(paths)\n            result_paths += to_result\n        if len(result_paths) == 0:\n            return None\n        best_path = self.__top_paths(result_paths, 1)[0]\n        return best_path.get_poem(self.vocabulary)\n\n    def generate_line_beam(self, path, beam_width=5):\n\n        path.metre_filter.reset()\n        paths = self.generate_paths(path, beam_width, use_rhyme=True)\n        result_paths = []\n        while len(paths) != 0:\n            paths = self.__top_paths(paths, beam_width)\n            for i, path in enumerate(copy.copy(paths)):\n                new_paths = self.generate_paths(path, beam_width, use_rhyme=False)\n                paths.pop(0)\n                paths += new_paths\n            paths, to_result = self.__filter_path_by_metre(paths)\n            result_paths += to_result\n        result_paths = self.__top_paths(result_paths, beam_width)\n        for i in range(len(result_paths)):\n            result_paths[i].put_line_end()\n        return result_paths\n\n    def generate_paths(self, path: BeamPath, beam_width: int=10, use_rhyme: bool=False):\n        \n\n        model = path.get_current_model(self.model_container, self.vocabulary, use_rhyme)\n        if np.sum(model) == 0.0:\n            return []\n        if len(path.indices) != 0:\n            new_indices = Generator.__choose(model, beam_width)\n        else:\n            new_indices = Generator.__choose_uniform(self.vocabulary.size(), beam_width)\n        new_paths = []\n        for index in new_indices:\n            word = self.vocabulary.get_word(index)\n            word_probability = model[index]\n            metre_filter = copy.copy(path.metre_filter)\n            metre_filter.pass_word(word)\n            rhyme_filter = copy.copy(path.rhyme_filter)\n            if use_rhyme:\n                #rhyme_filter.letters_to_rhymes = copy.deepcopy(path.rhyme_filter.letters_to_rhymes)\n                #rhyme_filter.letters_to_rhymes = path.rhyme_filter.letters_to_rhymes\n                rhyme_filter.pass_word(word)\n            new_paths.append(BeamPath(path.indices+[index], metre_filter, rhyme_filter,\n                                      path.probability * word_probability, copy.copy(path.line_ends)))\n        return new_paths\n\n    @staticmethod\n    def __top_paths(paths, n):\n        if len(paths) <= n:\n            return paths\n        max_indices = np.array([p.probability for p in paths]).argsort()[-n:][::-1]\n        max_paths = [path for i, path in enumerate(paths) if i in max_indices]\n        return max_paths\n\n    @staticmethod\n    def __filter_path_by_metre(paths):\n        result_paths = [path for path in paths if path.metre_filter.position == -1]\n        ok_paths = [path for path in paths if path.metre_filter.position > -1]\n        return ok_paths, result_paths\n\n    @staticmethod\n    def __filter_path_by_rhyme(paths):\n        result_paths = [path for path in paths if path.rhyme_filter.position == -1]\n        ok_paths = [path for path in paths if path.rhyme_filter.position > -1]\n        return ok_paths, result_paths\n\n    @staticmethod\n    def __choose_uniform(size: int, n: int = 1):\n        return [np.random.randint(1, size) for _ in range(n)]\n\n    @staticmethod\n    def __choose(model: np.array, n: int=1):\n        \n        norm_model = model / np.sum(model)\n        try:\n            return choice(range(len(norm_model)), n, p=norm_model, replace=False)\n        except ValueError:\n            return choice(range(len(norm_model)), n, p=norm_model, replace=True)\n\n    @staticmethod\n    def __top(model: np.array, n: int=1):\n        return [i for i in model.argsort()[-n:][::-1] if model[i] != 0.0]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:16:54.299088Z","iopub.execute_input":"2023-05-22T20:16:54.299460Z","iopub.status.idle":"2023-05-22T20:16:54.326273Z","shell.execute_reply.started":"2023-05-22T20:16:54.299418Z","shell.execute_reply":"2023-05-22T20:16:54.325172Z"},"trusted":true},"execution_count":512,"outputs":[]},{"cell_type":"code","source":"gen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abba\", n_syllables=8,\n                      letters_to_rhymes=None, beam_width=10, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:16:55.412371Z","iopub.execute_input":"2023-05-22T20:16:55.412999Z","iopub.status.idle":"2023-05-22T20:17:26.750617Z","shell.execute_reply.started":"2023-05-22T20:16:55.412926Z","shell.execute_reply":"2023-05-22T20:17:26.749443Z"},"trusted":true},"execution_count":513,"outputs":[{"name":"stdout","text":"И и и но и и меня\nИ мы так и и где меня шкафу внутри сердцам повинность\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(99)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abab\", n_syllables=8,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:17:26.752517Z","iopub.execute_input":"2023-05-22T20:17:26.753092Z","iopub.status.idle":"2023-05-22T20:18:30.463572Z","shell.execute_reply.started":"2023-05-22T20:17:26.753053Z","shell.execute_reply":"2023-05-22T20:18:30.462514Z"},"trusted":true},"execution_count":514,"outputs":[{"name":"stdout","text":"И и мы и что и давно\nКак и и но и мы меня ругу полочке шалью сокрыла\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"np.random.seed(98)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abab\", n_syllables=6,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:18:30.465120Z","iopub.execute_input":"2023-05-22T20:18:30.465488Z","iopub.status.idle":"2023-05-22T20:19:16.200714Z","shell.execute_reply.started":"2023-05-22T20:18:30.465443Z","shell.execute_reply":"2023-05-22T20:19:16.199753Z"},"trusted":true},"execution_count":515,"outputs":[{"name":"stdout","text":"И и мы ты давно\nИ и мы и давно полного окошком наконец свернутый\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(97)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abab\", n_syllables=6,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:19:16.205987Z","iopub.execute_input":"2023-05-22T20:19:16.208150Z","iopub.status.idle":"2023-05-22T20:20:01.329540Z","shell.execute_reply.started":"2023-05-22T20:19:16.208110Z","shell.execute_reply":"2023-05-22T20:20:01.328384Z"},"trusted":true},"execution_count":516,"outputs":[{"name":"stdout","text":"И и как и будто\nНу и и и давно козырной зловещая трюме этажа\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(95)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"aa\", n_syllables=6,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:20:01.331091Z","iopub.execute_input":"2023-05-22T20:20:01.331435Z","iopub.status.idle":"2023-05-22T20:20:24.208914Z","shell.execute_reply.started":"2023-05-22T20:20:01.331402Z","shell.execute_reply":"2023-05-22T20:20:24.207801Z"},"trusted":true},"execution_count":517,"outputs":[{"name":"stdout","text":"И и и но будто опахала портить означен монеты\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(95)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abba\", n_syllables=6,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:20:24.210243Z","iopub.execute_input":"2023-05-22T20:20:24.211810Z","iopub.status.idle":"2023-05-22T20:21:09.149219Z","shell.execute_reply.started":"2023-05-22T20:20:24.211772Z","shell.execute_reply":"2023-05-22T20:21:09.147970Z"},"trusted":true},"execution_count":518,"outputs":[{"name":"stdout","text":"И и и и будто\nИ и мне и давно опахала портить означен монеты\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(93)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abba\", n_syllables=6,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=4)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:21:49.187203Z","iopub.execute_input":"2023-05-22T20:21:49.187640Z","iopub.status.idle":"2023-05-22T20:22:35.449339Z","shell.execute_reply.started":"2023-05-22T20:21:49.187602Z","shell.execute_reply":"2023-05-22T20:22:35.448132Z"},"trusted":true},"execution_count":520,"outputs":[{"name":"stdout","text":"И и и что будто\nИ но и и только лихорадкой помчались мокрому являл\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(11)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abba\", n_syllables=8,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=2)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:23:06.691904Z","iopub.execute_input":"2023-05-22T20:23:06.692292Z","iopub.status.idle":"2023-05-22T20:24:10.101694Z","shell.execute_reply.started":"2023-05-22T20:23:06.692260Z","shell.execute_reply":"2023-05-22T20:24:10.100541Z"},"trusted":true},"execution_count":522,"outputs":[{"name":"stdout","text":"И и и и что и давно\nЯ и и и я и тебя дерзнула отдаст работай скверны\n\n","output_type":"stream"}]},{"cell_type":"code","source":"np.random.seed(22)\ngen = Generator(model_container, sv)\npoem = gen.generate_poem(metre_schema=\"+-\", rhyme_pattern=\"abba\", n_syllables=8,\n                      letters_to_rhymes=None, beam_width=20, rhyme_score_border=2)\nprint(poem)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T20:25:13.849519Z","iopub.execute_input":"2023-05-22T20:25:13.849841Z","iopub.status.idle":"2023-05-22T20:26:17.488890Z","shell.execute_reply.started":"2023-05-22T20:25:13.849813Z","shell.execute_reply":"2023-05-22T20:26:17.487769Z"},"trusted":true},"execution_count":524,"outputs":[{"name":"stdout","text":"И и что но и я давно\nИ я и и был и меня грозны соседство приветливых действовать\n\n","output_type":"stream"}]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T19:53:58.813962Z","iopub.execute_input":"2023-05-22T19:53:58.815020Z","iopub.status.idle":"2023-05-22T19:53:58.824150Z","shell.execute_reply.started":"2023-05-22T19:53:58.814981Z","shell.execute_reply":"2023-05-22T19:53:58.822865Z"},"trusted":true},"execution_count":508,"outputs":[{"execution_count":508,"output_type":"execute_result","data":{"text/plain":"__main__.LSTMModel"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}